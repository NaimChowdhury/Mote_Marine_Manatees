{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_nb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Uv0MDUSsuPL",
        "colab_type": "text"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdTVZr0WssyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch   \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ZCApzvN5uD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c201d912-af03-4e15-8ad5-8c9b6e7ab59f"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"Running on the GPU\")\n",
        "else: \n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Running on the CPU\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCqtfJUCsZ22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declate image size\n",
        "imsize = 105"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvZ2_t_BouNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount to Google Drive"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGSbtcHoaPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d4fd253e-7550-40a9-ae63-c4f117a27f1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPg8fktJo0pO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5310cded-5435-48bf-e3aa-f9997e4559a7"
      },
      "source": [
        "! ls '/content/drive/My Drive/Mote_Manatee'"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jul23.pth  MMLDUs_BatchA  out3.npy  out_jul23.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc0_u2rXo6gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the npy file\n",
        "manatee_data = np.load('/content/drive/My Drive/Mote_Manatee/out_jul23.npy', allow_pickle=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQV7OY1RpVgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "564256bf-067b-4a7c-aa7b-75ad779c6ea3"
      },
      "source": [
        "manatee_data.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1659, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG-53LpNAngd",
        "colab_type": "text"
      },
      "source": [
        "## Separate training and validation data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_f-Y2P2_kuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6a2bb7e-0b0d-4207-ae82-5de0231b943e"
      },
      "source": [
        "VAL_PCT = 0.1 # reserve 10% for validation\n",
        "val_size = int(manatee_data.shape[0]*VAL_PCT)\n",
        "print(val_size)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X9bJvax_7_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = manatee_data[:-val_size]\n",
        "validation_data = manatee_data[-val_size:]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh1csP7xsWJO",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset class loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpvIBigsd6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ManateeDataset(Dataset):\n",
        "  \"\"\" Manatee Dataset Class \"\"\"\n",
        "\n",
        "  def __init__(self, manatee_data, imsize, transform=None):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "        manatee_data (np array): numpy structured as (x1,x2,y)\n",
        "        transform (optional): optional transform to be applied on a sample\n",
        "    \"\"\"\n",
        "    self.manatee_data = manatee_data\n",
        "    self.transform = transform\n",
        "    self.imsize = imsize\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.manatee_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x1 = torch.Tensor(self.manatee_data[idx][0]).view(-1, self.imsize, self.imsize)\n",
        "    x2 = torch.Tensor(self.manatee_data[idx][1]).view(-1, self.imsize, self.imsize)\n",
        "    y = torch.Tensor(self.manatee_data[idx][2])\n",
        "    return x1, x2, y"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjEJhFQ7_ZZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = ManateeDataset(training_data, 105)\n",
        "val_data = ManateeDataset(validation_data, 105)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ot4ZtNr0LD",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Net Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA-3oy35sBg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Siamese(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Siamese, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 10),  # 64@96*96\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 64@48*48\n",
        "            nn.Conv2d(64, 128, 7),\n",
        "            nn.ReLU(),    # 128@42*42\n",
        "            nn.MaxPool2d(2),   # 128@21*21\n",
        "            nn.Conv2d(128, 128, 4),\n",
        "            nn.ReLU(), # 128@18*18\n",
        "            nn.MaxPool2d(2), # 128@9*9\n",
        "            nn.Conv2d(128, 256, 4),\n",
        "            nn.ReLU(),   # 256@6*6\n",
        "        )\n",
        "        self.liner = nn.Sequential(nn.Linear(9216, 4096), nn.Sigmoid())\n",
        "        self.out = nn.Linear(4096, 2)\n",
        "\n",
        "    def forward_both(self, x1, x2):\n",
        "      out1 = self.forward_one(x1)\n",
        "      out2 = self.forward_one(x2)\n",
        "      #euclidean_distance = F.pairwise_distance(out1, out2, keepdim = True)\n",
        "      cos = nn.CosineSimilarity()\n",
        "      output = cos(out1,out2)\n",
        "      return output\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        output = self.liner(x)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        out1 = self.forward_one(input1)\n",
        "        out2 = self.forward_one(input2)\n",
        "        return out1, out2"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHXbJYEeq8M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Siamese()\n",
        "# push to device\n",
        "#net = net.to(device)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA8CusJDsJGR",
        "colab_type": "text"
      },
      "source": [
        "# **Loss Function Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUhU6JiCrm0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "        return loss_contrastive"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHPC2YWragA",
        "colab_type": "text"
      },
      "source": [
        "## **Transform Data to PyTorch Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkhtVPNj0w2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "X2 = []\n",
        "for labeled_pair in range(training_data.shape[0]):\n",
        "  img1 = np.array(training_data[labeled_pair][1])\n",
        "  # append\n",
        "  X2.append(img1)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ca4t-GbFTI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X1 = torch.Tensor([training_data[labeled_pair][0] for labeled_pair in range(training_data.shape[0] )]).view(-1, imsize, imsize)\n",
        "#X2 = torch.Tensor([training_data[labeled_pair][1] for labeled_pair in range(training_data.shape[0] )]).view(-1, imsize, imsize)\n",
        "#y = torch.Tensor([training_data[labeled_pair][2] for labeled_pair in range(training_data.shape[0] )])\n",
        "\n",
        "#print(X1.shape)\n",
        "#print(X2.shape)\n",
        "#print(y.shape)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayb2zmFGs6Ii",
        "colab_type": "text"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GfPJIO0CUBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create DataLoader iterators\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=True, num_workers=2)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es9yceepFtTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders = {'train': train_loader, 'val':val_loader}\n",
        "dataset_sizes = {'train': training_data.shape[0], 'val': validation_data.shape[0]}"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2mXJMezFNsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for x1,x2,y in dataloaders[phase]:\n",
        "                #x1 = x1.to(device)\n",
        "                #x2 = x2.to(device)\n",
        "                #y = y.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    output1, output2 = model(x1,x2)\n",
        "                    # predict similarity \n",
        "                    preds = model.forward_both(x1,x2)\n",
        "                    # constrain (0-1)\n",
        "                    preds = torch.round(preds)\n",
        "                    # compute loss\n",
        "                    loss = criterion(output1, output2, y)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * x1.size(0)\n",
        "                running_corrects += torch.sum(preds == torch.max(y))\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiBZKaa3jK82",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWCUPqewXzYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = ContrastiveLoss()\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q61FPQ4VV8yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "16dcbd16-83c4-45a9-d4d8-9d9da3634ed9"
      },
      "source": [
        "# train and evaluate\n",
        "model = train_model(net, loss_function, optimizer, exp_lr_scheduler, num_epochs=20)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-dce45356951f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-04c27434770c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpQP8ROGHviL",
        "colab_type": "text"
      },
      "source": [
        "## **Test Trained Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1NejxQQRcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "535eb4f3-9e82-41db-d95a-668cbaaf4cbe"
      },
      "source": [
        "torch.save(model.state_dict, '/content/drive/My Drive/Mote_Manatee/jul23.pth')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Siamese. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLLwwlm0RbaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jerCUSF-HupJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneshot(model, img1,img2, imsize=105):\n",
        "  # Gives the feature vector of both inputs\n",
        "  output1, output2 = model(img1.view(-1,1,imsize,imsize),img2.view(-1,1,imsize,imsize))\n",
        "  # Compute the distance\n",
        "  euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "  print(euclidean_distance)\n"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}