{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_nb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Uv0MDUSsuPL",
        "colab_type": "text"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdTVZr0WssyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch   \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ZCApzvN5uD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "138d9eb4-98ed-471b-832c-79065b5ac709"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"Running on the GPU\")\n",
        "else: \n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Running on the CPU\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCqtfJUCsZ22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declate image size\n",
        "imsize = 105"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvZ2_t_BouNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount to Google Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGSbtcHoaPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "85b35ff4-b06d-4c08-d6d8-7e29194972bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPg8fktJo0pO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4706956b-e807-48e5-889c-2d26df4dd768"
      },
      "source": [
        "! ls '/content/drive/My Drive/Mote_Manatee'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jul23.pth  MMLDUs_BatchA  out3.npy  out_jul23.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc0_u2rXo6gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the npy file\n",
        "manatee_data = np.load('/content/drive/My Drive/Mote_Manatee/out_jul23.npy', allow_pickle=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQV7OY1RpVgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ef78df2-0183-4534-a0b2-b72af10d2333"
      },
      "source": [
        "manatee_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1659, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG-53LpNAngd",
        "colab_type": "text"
      },
      "source": [
        "## Separate training and validation data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_f-Y2P2_kuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68a19c06-3669-40ef-f297-8223c7b7f3fd"
      },
      "source": [
        "VAL_PCT = 0.1 # reserve 10% for validation\n",
        "val_size = int(manatee_data.shape[0]*VAL_PCT)\n",
        "print(val_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X9bJvax_7_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = manatee_data[:-val_size]\n",
        "validation_data = manatee_data[-val_size:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh1csP7xsWJO",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset class loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpvIBigsd6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ManateeDataset(Dataset):\n",
        "  \"\"\" Manatee Dataset Class \"\"\"\n",
        "\n",
        "  def __init__(self, manatee_data, imsize, transform=None):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "        manatee_data (np array): numpy structured as (x1,x2,y)\n",
        "        transform (optional): optional transform to be applied on a sample\n",
        "    \"\"\"\n",
        "    self.manatee_data = manatee_data\n",
        "    self.transform = transform\n",
        "    self.imsize = imsize\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.manatee_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x1 = torch.Tensor(self.manatee_data[idx][0]).view(-1, self.imsize, self.imsize)\n",
        "    x2 = torch.Tensor(self.manatee_data[idx][1]).view(-1, self.imsize, self.imsize)\n",
        "    y = torch.Tensor(self.manatee_data[idx][2])\n",
        "\n",
        "    if self.transform:\n",
        "      #norm = transforms.Normalize(mean=(0), std=(1))\n",
        "      x1 = x1/255.0\n",
        "      x2 = x2/255.0\n",
        "      y = torch.max(y).view(-1)\n",
        "\n",
        "    return x1, x2, y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjEJhFQ7_ZZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = ManateeDataset(training_data, 105, transform= True )\n",
        "val_data = ManateeDataset(validation_data, 105, transform= True )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC20VrudQhFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e61115a-2f98-4e9d-d37c-fa49b3328ec0"
      },
      "source": [
        "#torch.set_printoptions(profile=\"full\")\n",
        "x1, x2, y = train_data.__getitem__(0)\n",
        "y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ot4ZtNr0LD",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Net Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA-3oy35sBg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Siamese(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Siamese, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 10),  # 64@96*96\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 64@48*48\n",
        "            nn.Conv2d(64, 128, 7),\n",
        "            nn.ReLU(),    # 128@42*42\n",
        "            nn.MaxPool2d(2),   # 128@21*21\n",
        "            nn.Conv2d(128, 128, 4),\n",
        "            nn.ReLU(), # 128@18*18\n",
        "            nn.MaxPool2d(2), # 128@9*9\n",
        "            nn.Conv2d(128, 256, 4),\n",
        "            nn.ReLU(),   # 256@6*6\n",
        "        )\n",
        "        self.liner = nn.Sequential(nn.Linear(9216, 4096))\n",
        "        self.out = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "      out1 = self.forward_one(x1)\n",
        "      out2 = self.forward_one(x2)\n",
        "      L1_distance = torch.nn.PairwiseDistance(p=1, keepdim = True)\n",
        "      distance = L1_distance(out1, out2)\n",
        "      output = self.out(distance)\n",
        "      return output\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        output = self.liner(x)\n",
        "        return output\n",
        "\n",
        "    def forward_2(self, input1, input2):\n",
        "        out1 = self.forward_one(input1)\n",
        "        out2 = self.forward_one(input2)\n",
        "        return out1, out2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHXbJYEeq8M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Siamese()\n",
        "# push to device\n",
        "net = net.to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA8CusJDsJGR",
        "colab_type": "text"
      },
      "source": [
        "# **Loss Function Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUhU6JiCrm0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "        return loss_contrastive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHPC2YWragA",
        "colab_type": "text"
      },
      "source": [
        "## **Transform Data to PyTorch Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkhtVPNj0w2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "X2 = []\n",
        "for labeled_pair in range(training_data.shape[0]):\n",
        "  img1 = np.array(training_data[labeled_pair][1])\n",
        "  # append\n",
        "  X2.append(img1)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ca4t-GbFTI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X1 = torch.Tensor([training_data[labeled_pair][0] for labeled_pair in range(training_data.shape[0] )]).view(-1, imsize, imsize)\n",
        "#X2 = torch.Tensor([training_data[labeled_pair][1] for labeled_pair in range(training_data.shape[0] )]).view(-1, imsize, imsize)\n",
        "#y = torch.Tensor([training_data[labeled_pair][2] for labeled_pair in range(training_data.shape[0] )])\n",
        "\n",
        "#print(X1.shape)\n",
        "#print(X2.shape)\n",
        "#print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xZfJj0j9D9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0c2d5cad-2640-4778-fe76-de9148afe0e5"
      },
      "source": [
        "train_loader_tst = DataLoader(train_data, batch_size=1, shuffle=True, num_workers=2)\n",
        "net_tst = Siamese()\n",
        "\n",
        "for x1, x2, label in train_loader_tst:\n",
        "  out = net_tst(x1,x2)\n",
        "  print(out)\n",
        "  loss = torch.nn.functional.binary_cross_entropy(out, torch.max(label))\n",
        "  print(loss)\n",
        "  break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9868]], grad_fn=<SigmoidBackward>)\n",
            "tensor(0.0133, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayb2zmFGs6Ii",
        "colab_type": "text"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GfPJIO0CUBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create DataLoader iterators\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es9yceepFtTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders = {'train': train_loader, 'val':val_loader}\n",
        "dataset_sizes = {'train': training_data.shape[0], 'val': validation_data.shape[0]}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2mXJMezFNsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for x1,x2,y in dataloaders[phase]:\n",
        "                x1 = x1.to(device)\n",
        "                x2 = x2.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                \n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # net.forward()\n",
        "                    preds = model(x1,x2)\n",
        "                    # compute loss\n",
        "                    loss = torch.nn.functional.binary_cross_entropy(preds, y)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * x1.size(0)\n",
        "                running_corrects += torch.sum(preds == y)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiBZKaa3jK82",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWCUPqewXzYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr = 0.00006)\n",
        "#loss_function = ContrastiveLoss()\n",
        "#loss_function = torch.nn.functional.binary_cross_entropy()\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q61FPQ4VV8yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebeb1ee8-a34b-44d4-9afd-354c1abec122"
      },
      "source": [
        "# train and evaluate\n",
        "model = train_model(net, optimizer, exp_lr_scheduler, num_epochs=20)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.0004 Acc: 0.8434\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9880\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9880\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9880\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9880\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.0000 Acc: 0.9886\n",
            "val Loss: 0.0000 Acc: 0.9697\n",
            "\n",
            "Training complete in 0m 50s\n",
            "Best val Acc: 0.969697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpQP8ROGHviL",
        "colab_type": "text"
      },
      "source": [
        "## **Test Trained Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1NejxQQRcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "535eb4f3-9e82-41db-d95a-668cbaaf4cbe"
      },
      "source": [
        "torch.save(model.state_dict, '/content/drive/My Drive/Mote_Manatee/jul23.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Siamese. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLLwwlm0RbaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def support():\n",
        "  \"\"\" \n",
        "  Test Average N-way oneshot learning accuracy\n",
        "  \"\"\"\n",
        "  support_set = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udcR5LvJFlhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x1,x2,y in validation_data:\n",
        "  if y "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck6JnVsgD2T6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2682c9b3-f62e-4fc8-f170-20cc38e731e5"
      },
      "source": [
        "validation_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jerCUSF-HupJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneshot(model, img1,img2, imsize=105):\n",
        "  # Gives the feature vector of both inputs\n",
        "  output1, output2 = model(img1.view(-1,1,imsize,imsize),img2.view(-1,1,imsize,imsize))\n",
        "  # Compute the distance\n",
        "  euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "  print(euclidean_distance)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}