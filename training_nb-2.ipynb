{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_nb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Uv0MDUSsuPL",
        "colab_type": "text"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdTVZr0WssyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch   \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ZCApzvN5uD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc382189-2275-4039-bad7-ca530b155a65"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"Running on the GPU\")\n",
        "else: \n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Running on the CPU\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCqtfJUCsZ22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declate image size\n",
        "imsize = 105"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGSbtcHoaPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f07e4699-41f9-49c8-bd96-bd80f76faf6d"
      },
      "source": [
        "# Moun to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPg8fktJo0pO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "01d39f54-8319-411b-d9d1-bba744b01186"
      },
      "source": [
        "! ls '/content/drive/My Drive/Mote_Manatee'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alldata_aug2.npy  jul27.pth\t out3.npy\tpaired_aug2.npy\n",
            "jul23.pth\t  MMLDUs_BatchA  out_jul23.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc0_u2rXo6gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the npy files\n",
        "manatee_data = np.load('/content/drive/My Drive/Mote_Manatee/alldata_aug2.npy', allow_pickle=True)\n",
        "manatee_paired = np.load('/content/drive/My Drive/Mote_Manatee/paired_aug2.npy', allow_pickle=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaAysjr0H9vG",
        "colab_type": "text"
      },
      "source": [
        "Manatee_paired is all the found pairs in the dataset. Manatee_data is all the images in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQV7OY1RpVgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "09b3c6ff-197f-4be8-c4b2-514dc19bc439"
      },
      "source": [
        "print('Manatee_data shape is: ', manatee_data.shape)\n",
        "print('Manatee_paired data shape is: ',manatee_paired.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manatee_data shape is:  (1392, 105, 105)\n",
            "Manatee_paired data shape is:  (726, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBCj6K0FM9lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change label from index-base to 1-0\n",
        "\n",
        "for labeled_pair in manatee_paired:\n",
        "  label = labeled_pair[2].argmax()\n",
        "  labeled_pair[2] = label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6ZavusPZzrT",
        "colab_type": "text"
      },
      "source": [
        "## Make Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ_TNAghVCnY",
        "colab_type": "text"
      },
      "source": [
        "Since we need genuine pairs for testing accuracy. I will reserve 10% of genuine pairs from manatee_paired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWh_dKpuJMlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0962580-e74d-4c7c-8d27-12f90deb9098"
      },
      "source": [
        "# Reserve 10% of paired data for testing\n",
        "num_points = round(manatee_paired.shape[0] * 0.1) #73\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)\n",
        "# get 73 'random' numbers to use as indeces for manatee_paired data\n",
        "indices = np.random.choice(manatee_paired.shape[0], num_points, replace=False)\n",
        "test_paired = manatee_paired[indices]\n",
        "test_paired.shape\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqx1wSyGL6TA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fd490a1-d6db-4c7d-af42-caed42d2cf38"
      },
      "source": [
        "# get the remaining indices\n",
        "indices_to_remove = indices\n",
        "train_paired = np.delete(manatee_paired, indices_to_remove, axis=0)\n",
        "train_paired.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKEOV9cmU7Qp",
        "colab_type": "text"
      },
      "source": [
        "Now that the genuine pairs and all the images are available. I created this class to make the train-val dataset. The dataset will be a numpy array with each element being [img1, img2, label]. This dataset will include genuine and impostor pairs.\n",
        "\n",
        "Note: make_dataset() will always return all the imporstor pairs followed by all the genuine pairs. It is important to shuffle the data once it has been created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPpveCb9Z3tO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MakeTrainValData():\n",
        "  \"\"\"\n",
        "  This class is meant to make the train-val dataset by pairing impostor pairs and incorporating genuine pairs.\n",
        "  \"\"\"\n",
        "  def __init__(self, train_paired, all_data):\n",
        "    self.train_paired = train_paired\n",
        "    self.all_data = all_data\n",
        "\n",
        "  def make_dataset(self, pairs_per_image):\n",
        "    data = []\n",
        "\n",
        "    # make different pairs\n",
        "    for img in self.all_data:\n",
        "      img1 = img\n",
        "      for i in range(pairs_per_image):\n",
        "        random = np.random.randint(0, self.all_data.shape[0])\n",
        "        img2 = self.all_data[random]\n",
        "        label = 0\n",
        "\n",
        "        data.append([img1, img2, label])\n",
        "\n",
        "    # add labeled pairs\n",
        "    for labeled_pair in self.train_paired:\n",
        "      data.append(labeled_pair)\n",
        "\n",
        "    return np.asarray(data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjVakL5diUb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae4070e1-7368-419d-e551-1f2b173b395f"
      },
      "source": [
        "data = MakeTrainValData(train_paired, manatee_data)\n",
        "data = data.make_dataset(400)\n",
        "print(f'Dataset has been created, with {data.shape[0]} labeled pairs')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset has been created, with 557453 labeled pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eklQ03eumb1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebdaa6cc-5408-49cc-9fe6-59f543d5003b"
      },
      "source": [
        "# IMPORTANT! Shuffle dataset\n",
        "np.random.seed(10)\n",
        "shuffled_data = np.random.permutation(data)\n",
        "shuffled_data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(557453, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG-53LpNAngd",
        "colab_type": "text"
      },
      "source": [
        "## Separate train-val-test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGboeiJLnET9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "210f4885-46a8-4c21-aa3a-7900946653fd"
      },
      "source": [
        "val_num = round(shuffled_data.shape[0] * 0.1)\n",
        "train_num = round(shuffled_data.shape[0] * 0.9)\n",
        "print(f'Training data points: {train_num}')\n",
        "print(f'Validation data points: {val_num}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data points: 501708\n",
            "Validation data points: 55745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDneO2nlZzA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df6ec3d5-4660-4301-a2c6-531d3f523a37"
      },
      "source": [
        "###### GET TRAINING/VAL DATA POINTS\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)\n",
        "# get 501708 'random' numbers to use as indeces for shuffled_data\n",
        "indices = np.random.choice(shuffled_data.shape[0], train_num, replace=False)\n",
        "train_data = shuffled_data[indices]\n",
        "print(f'train_data shape is: {train_data.shape}')\n",
        "\n",
        "# drop train indices from shuffled_data, which are the val_data points\n",
        "indices_to_remove = indices\n",
        "val_data = np.delete(shuffled_data, indices_to_remove, axis=0)\n",
        "print(f'val_data shape is: {val_data.shape}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data shape is: (501708, 3)\n",
            "val_data shape is: (55745, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpW9q_CwKTx2",
        "colab_type": "text"
      },
      "source": [
        "## Compute mean and std for Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN-5yrRtKad8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainDataNormalize(Dataset):\n",
        "  def __init__(self, train_data, imsize=105, compute_mean_std=None):\n",
        "    self.train_data = train_data\n",
        "    self.imsize = imsize\n",
        "    self.compute_mean_std = compute_mean_std\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.train_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x1 = torch.Tensor(self.train_data[idx][0]).view(-1, self.imsize, self.imsize)\n",
        "    x2 = torch.Tensor(self.train_data[idx][1]).view(-1, self.imsize, self.imsize)\n",
        "    y = torch.Tensor([self.train_data[idx][2]])\n",
        "\n",
        "    if self.compute_mean_std:\n",
        "      return x1/255.0,x2/255.0\n",
        "    else:\n",
        "      return x1/255.0, x2/255.0, y"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ7vH5R3eA9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_compute = TrainDataNormalize(train_data, compute_mean_std=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCnEmj0CcdqR",
        "colab_type": "text"
      },
      "source": [
        "We need to manually implement the formulas for the mean and stantard deviation and iterate over small batches of the dataset.\n",
        "\n",
        "source: https://deeplizard.com/learn/video/lu7TCu7HeYc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkrQtcGJcX9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0953d34-8bd1-4ea6-efbe-d9793fffb9e6"
      },
      "source": [
        "# First, we create a data loader with a small batch size\n",
        "loader = DataLoader(train_data_compute, batch_size=1000, num_workers=1)\n",
        "\n",
        "# Then, we calculate our n value or total number of pixels\n",
        "num_of_pixels = train_num * 105 * 105   #Note that 105*105 is the height and width of the images in the dataset\n",
        "\n",
        "# Now we sum the pixel values by iterating over each batch,\n",
        "# and we calculate the mean by dividing this sum by the total num of pixels\n",
        "total_sum = 0\n",
        "for batch in loader: total_sum += batch[0].sum()\n",
        "mean = total_sum/num_of_pixels\n",
        "\n",
        "# Next we calculate the sum of the squared errors by iterating\n",
        "# through each batch. This allows us to calculate st by dividing\n",
        "# the sum of the squared errors by the total number of pixels and \n",
        "# square rooting the result\n",
        "\n",
        "sum_of_squared_error = 0\n",
        "for batch in loader:\n",
        "  sum_of_squared_error += ((batch[0] - mean).pow(2)).sum()\n",
        "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
        "\n",
        "\n",
        "print(f'mean is {mean}, std is {std}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean is 0.9760749936103821, std is 0.12026530504226685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh1csP7xsWJO",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset class loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpvIBigsd6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainValDataset(Dataset):\n",
        "  \"\"\" Manatee Dataset Class \"\"\"\n",
        "\n",
        "  def __init__(self, manatee_data, imsize, transform=None):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "        manatee_data (np array): numpy structured as (x1,x2,y)\n",
        "        transform (optional): optional transform to be applied on a sample\n",
        "    \"\"\"\n",
        "    self.manatee_data = manatee_data\n",
        "    self.transform = transform\n",
        "    self.imsize = imsize\n",
        "    #self.mean = mean \n",
        "    #self.std = std\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.manatee_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x1 = torch.Tensor(self.manatee_data[idx][0]).view(-1, self.imsize, self.imsize)\n",
        "    x2 = torch.Tensor(self.manatee_data[idx][1]).view(-1, self.imsize, self.imsize)\n",
        "    y = torch.Tensor([self.manatee_data[idx][2]])\n",
        "\n",
        "    if self.transform:\n",
        "      x1_normal = x1/255.0\n",
        "      x2_normal = x2/255.0\n",
        "      x1 = self.transform(x1_normal)\n",
        "      x2 = self.transform(x2_normal)\n",
        "\n",
        "    return x1, x2, y"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwRvNskTSZri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_class = TrainValDataset(train_data, 105, transform=transforms.Normalize(mean=[mean], std=[std]))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZQY6B8S_I6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "2bac401c-6331-4073-888d-246afc26f311"
      },
      "source": [
        "# Train data class example:\n",
        "train_data_class.__getitem__(0)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          ...,\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989]]]),\n",
              " tensor([[[0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          ...,\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989]]]),\n",
              " tensor([0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjEJhFQ7_ZZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_class = TrainValDataset(val_data, 105, transform=transforms.Normalize(mean=[mean], std=[std]))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka2Ms04Ocrzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e760de12-ef3f-4e4e-aff5-e1c11e0e0a03"
      },
      "source": [
        "# Val data class example:\n",
        "val_data_class.__getitem__(0)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          ...,\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989]]]),\n",
              " tensor([[[0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          ...,\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989],\n",
              "          [0.1989, 0.1989, 0.1989,  ..., 0.1989, 0.1989, 0.1989]]]),\n",
              " tensor([0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ot4ZtNr0LD",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Net Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA-3oy35sBg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Siamese(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Siamese, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 10),  # 64@96*96\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # 64@48*48\n",
        "            nn.Conv2d(64, 128, 7),\n",
        "            nn.ReLU(),    # 128@42*42\n",
        "            nn.MaxPool2d(2),   # 128@21*21\n",
        "            nn.Conv2d(128, 128, 4),\n",
        "            nn.ReLU(), # 128@18*18\n",
        "            nn.MaxPool2d(2), # 128@9*9\n",
        "            nn.Conv2d(128, 256, 4),\n",
        "            nn.ReLU(),   # 256@6*6\n",
        "        )\n",
        "        self.linear = nn.Sequential(nn.Linear(9216, 4096)) #512 out\n",
        "        #self.dropout = nn.Dropout(0.5)\n",
        "        self.out = nn.Sequential(nn.Linear(4096, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward2(self, x1, x2):\n",
        "      out1 = self.forward_one(x1)\n",
        "      out2 = self.forward_one(x2)\n",
        "      #L2_distance = torch.nn.PairwiseDistance(p=2, keepdim = True)\n",
        "      #distance = L2_distance(out1, out2)\n",
        "      #out = self.out(distance)\n",
        "      cos = nn.CosineSimilarity(eps=1e-6)\n",
        "      # similarity metric CV SDM\n",
        "      out = cos(out1,out2)\n",
        "      return out\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        out = self.linear(x)\n",
        "        #output = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        out1 = self.forward_one(input1)\n",
        "        out2 = self.forward_one(input2)\n",
        "        L1_distance = torch.abs(out1 - out2)\n",
        "        output = self.out(L1_distance)\n",
        "        return output"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHXbJYEeq8M-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ace5c8f-cf55-493a-d5ac-0924e0db9656"
      },
      "source": [
        "net = Siamese()\n",
        "# push to device\n",
        "net = net.to(device)\n",
        "print(sum(p.numel() for p in net.parameters()))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38951745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA8CusJDsJGR",
        "colab_type": "text"
      },
      "source": [
        "## Alternative Loss Function (Contrastive Loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUhU6JiCrm0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2, p=1, keepdim = True)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "        return loss_contrastive\n",
        "\n",
        "class ContrastiveLoss2(nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss\n",
        "    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(ContrastiveLoss2, self).__init__()\n",
        "        self.margin = 0.2\n",
        "        self.eps = 1e-9\n",
        "\n",
        "    def forward(self, output1, output2, target, size_average=True):\n",
        "        distances = (output2 - output1).pow(2).sum(1)  # squared distances\n",
        "        losses = 0.5 * (target.float() * distances +\n",
        "                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
        "        return losses.mean() if size_average else losses.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2bHpIUMz_Vo",
        "colab_type": "text"
      },
      "source": [
        "Margin in contrastive loss is more like regulirization constraint it defines hypersphere radius where all similar samples should locate .So from this point of view learning the margin will lead to overtraining “ bias-variance problem”. \n",
        "\n",
        "You can just normalize features using L2 before using Contrastive Loss. Then the margin can be constant while training because the distance between features will be normalized. You can of course change margin in dynamic way, but I do not think it will gain any boost. Idea from A Unified Embedding for Face Recognition and Clustering (although they use Triplet Loss, the same idea can be used in Siamese Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHPC2YWragA",
        "colab_type": "text"
      },
      "source": [
        "## Forward pass test example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xZfJj0j9D9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d4f2b1cb-abb4-492a-9dc6-1a1ecd6901f6"
      },
      "source": [
        "train_loader_tst = DataLoader(train_data_class, batch_size=1, shuffle=True, num_workers=1)\n",
        "net_tst = Siamese()\n",
        "\n",
        "for x1, x2, label in train_loader_tst:\n",
        "  out = net_tst(x1,x2)\n",
        "  print(out)\n",
        "  loss = torch.nn.functional.binary_cross_entropy(out, label)\n",
        "  print(loss)\n",
        "  break\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4955]], grad_fn=<SigmoidBackward>)\n",
            "tensor(0.6843, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayb2zmFGs6Ii",
        "colab_type": "text"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GfPJIO0CUBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create DataLoader iterators\n",
        "train_loader = DataLoader(train_data_class, batch_size=64, shuffle=True, num_workers=2) \n",
        "val_loader = DataLoader(val_data_class, batch_size=64, shuffle=True, num_workers=2)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es9yceepFtTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders = {'train': train_loader, 'val':val_loader}\n",
        "dataset_sizes = {'train': train_data.shape[0], 'val': val_data.shape[0]}"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2mXJMezFNsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 0.0\n",
        "    #best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            #running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for x1,x2,y in dataloaders[phase]:\n",
        "                x1 = x1.to(device)\n",
        "                x2 = x2.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                \n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # net.forward()\n",
        "                    preds = model(x1,x2)\n",
        "                    # compute loss\n",
        "                    #loss = criterion(out1,out2, y)\n",
        "                    loss = torch.nn.functional.binary_cross_entropy(preds, y)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * x1.size(0)\n",
        "                #running_corrects += torch.sum(preds == y)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f}'.format(\n",
        "                phase, epoch_loss)) #epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiBZKaa3jK82",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWCUPqewXzYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr = 0.05, weight_decay=1e-2) #lr = 0.00006)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q61FPQ4VV8yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "3c59a345-a3b5-41c1-d160-cbc3069296ac"
      },
      "source": [
        "# train and evaluate\n",
        "model = train_model(net, optimizer, exp_lr_scheduler)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-d4680188dc44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-98-886234c28ba0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;31m#running_corrects += torch.sum(preds == y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpQP8ROGHviL",
        "colab_type": "text"
      },
      "source": [
        "## **Test Trained Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNzGaprejvkY",
        "colab_type": "text"
      },
      "source": [
        "- Look for architecture (first)\n",
        "- Bayesian optimization \n",
        "- data augmentation\n",
        "- lr finder\n",
        "- weight decay and L2 (optimizer)\n",
        "- check Adam vs SGD with momentum with warm restarts (after lr finder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1NejxQQRcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "72d4d935-5a50-4eba-92e4-777f8f7404af"
      },
      "source": [
        "torch.save(model.state_dict, '/content/drive/My Drive/Mote_Manatee/jul27.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Siamese. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okrDXIgLOXjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6001a24a-451f-4a6d-c97d-5d094c53d22b"
      },
      "source": [
        "! ls '/content/drive/My Drive/Mote_Manatee'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jul23.pth  jul27.pth  MMLDUs_BatchA  out3.npy  out_jul23.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLLwwlm0RbaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def support():\n",
        "  \"\"\" \n",
        "  Test Average N-way oneshot learning accuracy\n",
        "  \"\"\"\n",
        "  support_set = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOI5YYRfO31-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "86bbf5da-12f8-4a7d-9bc7-21f589639f59"
      },
      "source": [
        "val_tst = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "for x1, x2, label in val_tst:\n",
        "  x1 = x1.to(device)\n",
        "  x2 = x2.to(device)\n",
        "  label = label.to(device)\n",
        "  print(label)\n",
        "  out = model.forward2(x1,x2)\n",
        "  print(out)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0]], device='cuda:0')\n",
            "tensor([0.9981, 0.9961, 0.9957, 0.9990, 0.9990, 0.9986, 0.9983, 0.9955, 0.9973,\n",
            "        0.9998, 0.9979, 0.9974, 0.9996, 0.9987, 0.9984, 0.9990, 0.9982, 0.9989,\n",
            "        0.9988, 0.9989, 0.9971, 0.9977, 0.9973, 0.9966, 0.9965, 0.9958, 0.9958,\n",
            "        0.9994, 0.9973, 0.9979, 0.9994, 0.9979], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9EDX4JRO3cF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udcR5LvJFlhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "1aa63887-ac48-4d1d-d17d-04bdd8e6212e"
      },
      "source": [
        "for x1,x2,y val_data[0]:\n",
        "  print(y)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-981d0a1f257a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for x1,x2,y val_data[0]:\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck6JnVsgD2T6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2682c9b3-f62e-4fc8-f170-20cc38e731e5"
      },
      "source": [
        "validation_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jerCUSF-HupJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneshot(model, img1,img2, imsize=105):\n",
        "  # Gives the feature vector of both inputs\n",
        "  output1, output2 = model(img1.view(-1,1,imsize,imsize),img2.view(-1,1,imsize,imsize))\n",
        "  # Compute the distance\n",
        "  euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "  print(euclidean_distance)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}